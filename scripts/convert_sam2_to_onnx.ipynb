{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# SAM2 to ONNX/ORT Conversion\n\nThis notebook converts SAM2 (Segment Anything Model 2) checkpoints to ONNX and ORT\nformat for browser-based inference in NimbusImage.\n\nIt exports both **encoder** and **decoder** for the **Base+** and **Large** variants.\nEncoders are then converted from `.onnx` to `.ort` (ORT's pre-optimized format),\nwhich is required for the onnxruntime-web WebGPU backend.\n\nAfter running all cells, download the encoder `.ort` and decoder `.onnx` files."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone repos and install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/vietanhdev/samexporter.git\n",
    "!git clone https://github.com/facebookresearch/sam2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pin PyTorch 2.5.1 to use the legacy TorchScript-based ONNX exporter.\n# PyTorch 2.6+ defaults to the dynamo exporter, which runs onnxscript\n# constant folding that gets stuck on Resize ops (hours of pure-Python pixel work).\n!pip install torch==2.5.1 torchvision==0.20.1\n!pip install -e ./sam2\n!pip install onnx onnxruntime timm onnxsim"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Download SAM2 checkpoints (Base+ and Large)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nos.makedirs('original_models', exist_ok=True)\nos.makedirs('output_models', exist_ok=True)\n\n!wget -q --show-progress -O original_models/sam2_hiera_base_plus.pt \\\n    https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt\n\n!wget -q --show-progress -O original_models/sam2_hiera_large.pt \\\n    https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\n\n!ls -lh original_models/"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Export Base+ model to ONNX"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%cd samexporter\n\n!python -m samexporter.export_sam2 \\\n    --checkpoint ../original_models/sam2_hiera_base_plus.pt \\\n    --output_encoder ../output_models/sam2_hiera_base_plus.encoder.onnx \\\n    --output_decoder ../output_models/sam2_hiera_base_plus.decoder.onnx \\\n    --model_type sam2_hiera_base_plus\n\n%cd .."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Export Large model to ONNX"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%cd samexporter\n\n!python -m samexporter.export_sam2 \\\n    --checkpoint ../original_models/sam2_hiera_large.pt \\\n    --output_encoder ../output_models/sam2_hiera_large.encoder.onnx \\\n    --output_decoder ../output_models/sam2_hiera_large.decoder.onnx \\\n    --model_type sam2_hiera_large\n\n%cd .."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Convert encoders from ONNX to ORT format\n\nThe onnxruntime-web WebGPU backend cannot load raw `.onnx` encoder models at\nruntime (graph optimization fails silently). The `.ort` format has optimizations\npre-baked, so ORT can load it directly.\n\nWe use `onnxruntime.tools.convert_onnx_models_to_ort` to do this offline."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import onnxruntime as ort\n\nfor model_name in ['sam2_hiera_base_plus', 'sam2_hiera_large']:\n    encoder_onnx = f'output_models/{model_name}.encoder.onnx'\n    encoder_ort = f'output_models/{model_name}.encoder.ort'\n\n    print(f'Converting {encoder_onnx} -> {encoder_ort} ...')\n\n    # Use ORT_ENABLE_BASIC to apply standard graph optimizations (constant\n    # folding, redundant node elimination) WITHOUT provider-specific transforms.\n    # ORT_ENABLE_ALL would insert CPU-specific ops (e.g. com.microsoft.nchwc:Conv)\n    # that the WebGPU backend doesn't support.\n    sess_options = ort.SessionOptions()\n    sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_BASIC\n    sess_options.optimized_model_filepath = encoder_ort\n\n    # Creating the session with an optimized_model_filepath saves the .ort file\n    ort.InferenceSession(encoder_onnx, sess_options, providers=['CPUExecutionProvider'])\n\n    ort_size = os.path.getsize(encoder_ort) / 1024 / 1024\n    print(f'  Saved {encoder_ort} ({ort_size:.1f} MB)')\n\nprint()\nprint('Done! Encoder .ort files ready.')\n!ls -lh output_models/"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Check output files"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!ls -lh output_models/"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Where to put the files\n\nAfter downloading, place the files in your NimbusImage project:\n\n```\npublic/onnx-models/sam/sam2_hiera_base_plus/encoder.ort      (from sam2_hiera_base_plus.encoder.ort)\npublic/onnx-models/sam/sam2_hiera_base_plus/decoder.onnx     (from sam2_hiera_base_plus.decoder.onnx)\npublic/onnx-models/sam/sam2_hiera_large/encoder.ort          (from sam2_hiera_large.encoder.ort)\npublic/onnx-models/sam/sam2_hiera_large/decoder.onnx         (from sam2_hiera_large.decoder.onnx)\n```\n\nNote: Encoders use `.ort` format (pre-optimized) because onnxruntime-web's WebGPU\nbackend cannot optimize raw `.onnx` encoder models at runtime.\n\nThe SAM1 ViT-B model files (`public/onnx-models/sam/vit_b/encoder.onnx` and\n`decoder.onnx`) should already be in place from the original SAM1 setup."
  },
  {
   "cell_type": "code",
   "source": "from google.colab import files\n\nfor f in [\n    'output_models/sam2_hiera_base_plus.encoder.ort',\n    'output_models/sam2_hiera_base_plus.decoder.onnx',\n    'output_models/sam2_hiera_large.encoder.ort',\n    'output_models/sam2_hiera_large.decoder.onnx',\n]:\n    if os.path.exists(f):\n        print(f'Downloading {f} ({os.path.getsize(f) / 1024 / 1024:.1f} MB)...')\n        files.download(f)\n    else:\n        print(f'WARNING: {f} not found!')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}